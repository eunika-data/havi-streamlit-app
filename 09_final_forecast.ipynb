{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd60ec7c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be37565c",
   "metadata": {},
   "source": [
    "09 final forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cd0653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM_FEATURES (from schema): 18\n",
      "CAT_FEATURES (from schema): ['country', 'sku']\n",
      "NUM_FEATURES: 18\n",
      "Lagi: ['lag_1', 'lag_13', 'lag_2', 'lag_4', 'lag_8']\n",
      "Rolle: ['roll_mean_13', 'roll_mean_4', 'roll_mean_8', 'roll_std_13', 'roll_std_4', 'roll_std_8']\n",
      "Series missing in df_hist (features): 6\n",
      "forecast_ml rows: 468\n",
      "forecast_ml model_type counts:\n",
      " model_type\n",
      "ml_recursive    468\n",
      "Name: count, dtype: int64\n",
      "Ile serii ML płaskich: 0 na 9\n",
      "Series OTHER in df_hist: 5\n",
      "bb_other rows: 260\n",
      "Saved: C:\\Users\\48573\\Desktop\\Programy_rozwój\\TopYoung100\\HAVI\\data\\forecast_future.parquet (1040, 10)\n",
      "model_type counts:\n",
      " model_type\n",
      "other_hybrid    572\n",
      "ml_recursive    468\n",
      "Name: count, dtype: int64\n",
      "Serie w forecast_all: 20\n",
      "SKU w forecast_all: 20\n",
      "Tygodnie 2026: 52 2026-01-05 00:00:00 2026-12-28 00:00:00\n",
      "\n",
      "[CHECK] Duplicate rows on (country,dc_id,sku,date): 0\n",
      "[CHECK] max rows per (country,sku,date): 1\n",
      "[CHECK] PI10 > PI90 rows: 0\n",
      "[CHECK] negative y_pred rows: 0\n",
      "[CHECK] share of y_pred == 0: 0.0\n",
      "[CHECK] flat series by std<=1e-6: 0 / 20\n",
      "\n",
      "DONE.\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 09_final_forecast.py\n",
    "# FINAL (po poprawkach):\n",
    "# - segmentacja automatyczna jak w 08\n",
    "# - OTHER -> baseline-best (NIE model_C)\n",
    "# - ML recursive tylko dla A/B/C\n",
    "# - flatness-fix: płaskie ML -> baseline-best\n",
    "# - fallback_last dla serii nieobecnych w df_hist (features)\n",
    "# =========================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", 50)\n",
    "\n",
    "DATA_DIR = Path(\"data\")\n",
    "FEAT_DIR = DATA_DIR / \"features\"\n",
    "BT_DIR   = DATA_DIR / \"backtesting\"\n",
    "MODEL_DIR = DATA_DIR / \"models\"\n",
    "\n",
    "HIST_PATH = FEAT_DIR / \"features_level_a.parquet\"          # musi zawierać: demand (TARGET_RAW)\n",
    "BASELINE_PATH = BT_DIR / \"baseline_best_per_series.parquet\"  # country, sku, best_baseline\n",
    "MASTER_RAW = DATA_DIR / \"master_raw.parquet\"               # musi zawierać: demand_raw\n",
    "\n",
    "OUT_FUTURE = DATA_DIR / \"forecast_future.parquet\"\n",
    "OUT_METRICS = DATA_DIR / \"metrics_summary.parquet\"         # (opcjonalnie, jeśli będziesz chciała dopisać)\n",
    "\n",
    "TARGET_RAW = \"demand\"              # w df_hist\n",
    "TARGET_RAW_FALLBACK = \"demand_raw\" # w master_raw\n",
    "CAT_FEATURES = [\"country\", \"sku\"]\n",
    "\n",
    "\n",
    "schema = joblib.load(MODEL_DIR / \"model_schema.pkl\")\n",
    "FEATURE_COLS = schema[\"feature_cols\"]\n",
    "CAT_FEATURES = schema[\"cat_features\"]\n",
    "NUM_FEATURES = schema[\"num_features\"]\n",
    "CAT_LEVELS = schema[\"cat_levels\"]\n",
    "\n",
    "# -------------------------\n",
    "# HELPERS\n",
    "# -------------------------\n",
    "def wape(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true, dtype=float)\n",
    "    y_pred = np.asarray(y_pred, dtype=float)\n",
    "    denom = np.abs(y_true).sum()\n",
    "    return np.nan if denom <= 1e-12 else np.abs(y_true - y_pred).sum() / denom\n",
    "\n",
    "\n",
    "def safe_impute_num(df, num_cols):\n",
    "    out = df.copy()\n",
    "    for c in num_cols:\n",
    "        if c not in out.columns:\n",
    "            out[c] = np.nan\n",
    "\n",
    "    grp = out.groupby([\"country\", \"sku\"], observed=True)\n",
    "    for c in num_cols:\n",
    "        out[c] = pd.to_numeric(out[c], errors=\"coerce\")\n",
    "        out[c] = out[c].fillna(grp[c].transform(\"median\"))\n",
    "        out[c] = out[c].fillna(out[c].median())\n",
    "\n",
    "    return out\n",
    "\n",
    "def rolling_mean_forecast(y_hist, horizon, window=8):\n",
    "    y = pd.to_numeric(y_hist, errors=\"coerce\").fillna(0.0)\n",
    "    if len(y) == 0:\n",
    "        return np.zeros(horizon)\n",
    "    w = min(window, len(y))\n",
    "    mu = float(y.iloc[-w:].mean())\n",
    "    return np.repeat(mu, horizon)\n",
    "\n",
    "def seasonal_naive_damped(y_hist, horizon, season=52, alpha=0.6):\n",
    "    \"\"\"\n",
    "    Mieszanka: alpha * seasonal_naive + (1-alpha) * last_value\n",
    "    Stabilniejsze, ale nie płaskie.\n",
    "    \"\"\"\n",
    "    y = pd.to_numeric(y_hist, errors=\"coerce\").fillna(0.0)\n",
    "    s = seasonal_naive(y, horizon, season=season)\n",
    "    last = naive_last(y, horizon)\n",
    "    return alpha * s + (1 - alpha) * last\n",
    "\n",
    "def hybrid_other_forecast(y_hist, horizon):\n",
    "    \"\"\"\n",
    "    Szybka reguła dla OTHER / fallback:\n",
    "    - dużo historii: seasonal_naive_damped + lekki drift\n",
    "    - średnio: seasonal_naive_damped\n",
    "    - mało: rolling mean + mini drift\n",
    "    \"\"\"\n",
    "    y = pd.to_numeric(y_hist, errors=\"coerce\").fillna(0.0).reset_index(drop=True)\n",
    "    n = len(y)\n",
    "\n",
    "    if n >= 104:\n",
    "        base = seasonal_naive_damped(y, horizon, season=52, alpha=0.7)\n",
    "        d = drift(y, horizon)\n",
    "        # lekki trend (20% driftu)\n",
    "        return 0.8 * base + 0.2 * d\n",
    "\n",
    "    if n >= 52:\n",
    "        return seasonal_naive_damped(y, horizon, season=52, alpha=0.7)\n",
    "\n",
    "    # krótkie serie\n",
    "    base = rolling_mean_forecast(y, horizon, window=8)\n",
    "    d = drift(y, horizon)\n",
    "    return 0.85 * base + 0.15 * d\n",
    "\n",
    "\n",
    "BASE_NUM = [\n",
    "    \"n_dc\",\"week_sin\",\"week_cos\",\"zero_share\",\"ADI\",\"CV2\",\n",
    "    \"weeks_since_nonzero\",\"is_zero\",\"is_outlier\"\n",
    "]\n",
    "KEEP_LAGS = {1,2,4,8,13}\n",
    "KEEP_ROLLS = {4,8,13}\n",
    "\n",
    "def naive_last(y_hist, horizon):\n",
    "    last = float(y_hist.iloc[-1]) if len(y_hist) else 0.0\n",
    "    return np.repeat(last, horizon)\n",
    "\n",
    "def seasonal_naive(y_hist, horizon, season=52):\n",
    "    if len(y_hist) < season:\n",
    "        return naive_last(y_hist, horizon)\n",
    "    start = len(y_hist) - season\n",
    "    return y_hist.iloc[start:start + horizon].values[:horizon]\n",
    "\n",
    "def drift(y_hist, horizon):\n",
    "    if len(y_hist) < 2:\n",
    "        return naive_last(y_hist, horizon)\n",
    "    slope = (float(y_hist.iloc[-1]) - float(y_hist.iloc[0])) / (len(y_hist) - 1)\n",
    "    return float(y_hist.iloc[-1]) + slope * np.arange(1, horizon + 1)\n",
    "\n",
    "def make_best_baseline_forecast_2026(raw_df, baseline_df):\n",
    "    \"\"\"\n",
    "    raw_df: master_raw.parquet (country, sku, week_start, demand_raw)\n",
    "    baseline_df: baseline_best_per_series.parquet (country, sku, best_baseline)\n",
    "    \"\"\"\n",
    "    dates_2026 = pd.date_range(\"2026-01-05\", \"2026-12-28\", freq=\"W-MON\")\n",
    "    horizon = len(dates_2026)\n",
    "\n",
    "    out_rows = []\n",
    "    baseline_map = baseline_df.set_index([\"country\",\"sku\"])[\"best_baseline\"].to_dict()\n",
    "\n",
    "    for (c, sku), g in raw_df.groupby([\"country\",\"sku\"], observed=True):\n",
    "        g = g.sort_values(\"week_start\")\n",
    "        y = pd.to_numeric(g[TARGET_RAW_FALLBACK], errors=\"coerce\").fillna(0.0).reset_index(drop=True)\n",
    "\n",
    "        model = str(baseline_map.get((c, sku), \"naive\")).strip().lower()\n",
    "        if model == \"seasonal_naive\":\n",
    "            preds = seasonal_naive(y, horizon, season=52)\n",
    "        elif model == \"drift\":\n",
    "            preds = drift(y, horizon)\n",
    "        else:\n",
    "            preds = naive_last(y, horizon)\n",
    "\n",
    "        sigma = float(np.std(y.values, ddof=0)) if len(y) else 0.0\n",
    "        k = 1.28\n",
    "\n",
    "        for d, yp in zip(dates_2026, preds):\n",
    "            yp = max(0.0, float(yp))\n",
    "            p10 = max(0.0, yp - k*sigma)\n",
    "            p90 = max(0.0, yp + k*sigma)\n",
    "\n",
    "            out_rows.append({\n",
    "                \"country\": c,\n",
    "                \"dc_id\": \"ALL\",\n",
    "                \"sku\": sku,\n",
    "                \"product_name\": None,\n",
    "                \"segment\": None,\n",
    "                \"date\": d,\n",
    "                \"y_pred\": yp,\n",
    "                \"PI10\": p10,\n",
    "                \"PI90\": p90,\n",
    "                \"model_type\": f\"baseline_{model}\",\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(out_rows)\n",
    "\n",
    "\n",
    "def fallback_forecast_2026(raw_df, series_df):\n",
    "    dates_2026 = pd.date_range(\"2026-01-05\", \"2026-12-28\", freq=\"W-MON\")\n",
    "    horizon = len(dates_2026)\n",
    "    out_rows = []\n",
    "\n",
    "    for _, s in series_df.iterrows():\n",
    "        c, sku = s[\"country\"], s[\"sku\"]\n",
    "        g = raw_df[(raw_df[\"country\"].astype(str)==str(c)) & (raw_df[\"sku\"].astype(str)==str(sku))].copy()\n",
    "        g = g.sort_values(\"week_start\")\n",
    "        y = pd.to_numeric(g[TARGET_RAW_FALLBACK], errors=\"coerce\").fillna(0.0).reset_index(drop=True)\n",
    "\n",
    "        preds = hybrid_other_forecast(y, horizon)\n",
    "\n",
    "        sigma = float(np.std(y.values, ddof=0)) if len(y) else 0.0\n",
    "        k = 1.28\n",
    "\n",
    "        for d, yp in zip(dates_2026, preds):\n",
    "            yp = max(0.0, float(yp))\n",
    "            p10 = max(0.0, yp - k*sigma)\n",
    "            p90 = max(0.0, yp + k*sigma)\n",
    "\n",
    "            out_rows.append({\n",
    "                \"country\": c,\n",
    "                \"dc_id\": \"ALL\",\n",
    "                \"sku\": sku,\n",
    "                \"product_name\": s.get(\"product_name\", None),\n",
    "                \"segment\": \"FALLBACK\",\n",
    "                \"date\": d,\n",
    "                \"y_pred\": yp,\n",
    "                \"PI10\": p10,\n",
    "                \"PI90\": p90,\n",
    "                \"model_type\": \"other_hybrid\"\n",
    "            })\n",
    "    return pd.DataFrame(out_rows)\n",
    "\n",
    "def other_forecast_2026_from_raw(raw_df, other_keys_df):\n",
    "    dates_2026 = pd.date_range(\"2026-01-05\", \"2026-12-28\", freq=\"W-MON\")\n",
    "    horizon = len(dates_2026)\n",
    "    out_rows = []\n",
    "\n",
    "    for _, r in other_keys_df.iterrows():\n",
    "        c = str(r[\"country\"])\n",
    "        sku = str(r[\"sku\"])\n",
    "\n",
    "        g = raw_df[(raw_df[\"country\"].astype(str)==c) & (raw_df[\"sku\"].astype(str)==sku)].copy()\n",
    "        g = g.sort_values(\"week_start\")\n",
    "        y = pd.to_numeric(g[TARGET_RAW_FALLBACK], errors=\"coerce\").fillna(0.0).reset_index(drop=True)\n",
    "\n",
    "        preds = hybrid_other_forecast(y, horizon)\n",
    "\n",
    "        sigma = float(np.std(y.values, ddof=0)) if len(y) else 0.0\n",
    "        k = 1.28\n",
    "\n",
    "        product_name = None\n",
    "        if \"product_name\" in g.columns and len(g):\n",
    "            product_name = str(g[\"product_name\"].dropna().iloc[-1]) if g[\"product_name\"].notna().any() else None\n",
    "\n",
    "        for d, yp in zip(dates_2026, preds):\n",
    "            yp = max(0.0, float(yp))\n",
    "            p10 = max(0.0, yp - k*sigma)\n",
    "            p90 = max(0.0, yp + k*sigma)\n",
    "\n",
    "            out_rows.append({\n",
    "                \"country\": c,\n",
    "                \"dc_id\": \"ALL\",\n",
    "                \"sku\": sku,\n",
    "                \"product_name\": product_name,\n",
    "                \"segment\": \"OTHER\",\n",
    "                \"date\": d,\n",
    "                \"y_pred\": yp,\n",
    "                \"PI10\": p10,\n",
    "                \"PI90\": p90,\n",
    "                \"model_type\": \"other_hybrid\"\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(out_rows)\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# LOAD DATA + MODELS\n",
    "# -------------------------\n",
    "df_hist = pd.read_parquet(HIST_PATH)\n",
    "df_base = pd.read_parquet(BASELINE_PATH)\n",
    "\n",
    "if \"baseline_wape\" not in df_base.columns and \"wape\" in df_base.columns:\n",
    "    df_base = df_base.rename(columns={\"wape\": \"baseline_wape\"})\n",
    "\n",
    "model_A = joblib.load(MODEL_DIR / \"lgbm_segment_A.pkl\")\n",
    "model_B = joblib.load(MODEL_DIR / \"lgbm_segment_B.pkl\")\n",
    "model_C = joblib.load(MODEL_DIR / \"lgbm_segment_C.pkl\")\n",
    "models = {\"A\": model_A, \"B\": model_B, \"C\": model_C}\n",
    "\n",
    "df_hist[\"week_start\"] = pd.to_datetime(df_hist[\"week_start\"], errors=\"coerce\")\n",
    "df_hist = df_hist[df_hist[\"week_start\"].notna()].copy()\n",
    "\n",
    "# (opcjonalne) Twoje mapowanie nazw\n",
    "df_hist[\"product_name\"] = df_hist[\"product_name\"].replace({\n",
    "    \"*GAZPACHO\": \"GAZPACHO (17783-000)\"\n",
    "})\n",
    "\n",
    "missing_num = [c for c in NUM_FEATURES if c not in df_hist.columns]\n",
    "if missing_num:\n",
    "    for c in missing_num:\n",
    "        df_hist[c] = np.nan  # do imputacji później\n",
    "\n",
    "df_hist[TARGET_RAW] = pd.to_numeric(df_hist[TARGET_RAW], errors=\"coerce\").fillna(0.0).clip(lower=0.0)\n",
    "df_hist = safe_impute_num(df_hist, NUM_FEATURES)\n",
    "\n",
    "print(\"NUM_FEATURES (from schema):\", len(NUM_FEATURES))\n",
    "print(\"CAT_FEATURES (from schema):\", CAT_FEATURES)\n",
    "\n",
    "print(\"NUM_FEATURES:\", len(NUM_FEATURES))\n",
    "print(\"Lagi:\", [c for c in NUM_FEATURES if c.startswith(\"lag_\")])\n",
    "print(\"Rolle:\", [c for c in NUM_FEATURES if c.startswith(\"roll_\")])\n",
    "\n",
    "# -------------------------\n",
    "# SEGMENTATION (AUTO like 08)\n",
    "# -------------------------\n",
    "profile = (\n",
    "    df_hist\n",
    "    .groupby([\"product_name\", \"country\"], observed=True)\n",
    "    .agg(\n",
    "        mean=(TARGET_RAW, \"mean\"),\n",
    "        cv=(TARGET_RAW, lambda s: float(np.nanstd(s) / (np.nanmean(s) + 1e-9))),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "SEG_A_SET = set(profile.loc[(profile[\"mean\"] >= 1500) & (profile[\"cv\"] <= 0.3), \"product_name\"].astype(str))\n",
    "SEG_B_SET = set(profile.loc[(profile[\"mean\"] < 1500) & (profile[\"mean\"] >= 200) & (profile[\"cv\"] > 0.3) & (profile[\"cv\"] <= 0.7), \"product_name\"].astype(str))\n",
    "SEG_C_SET = set(profile.loc[(profile[\"mean\"] < 200) & (profile[\"cv\"] > 0.7), \"product_name\"].astype(str))\n",
    "\n",
    "def assign_segment(product_name: str) -> str:\n",
    "    p = str(product_name)\n",
    "    if p in SEG_A_SET: return \"A\"\n",
    "    if p in SEG_B_SET: return \"B\"\n",
    "    if p in SEG_C_SET: return \"C\"\n",
    "    return \"OTHER\"   # kluczowa zmiana vs Twoje stare 09\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# STATIC NUM FEATURES (bez lagów/rolli/week trig)\n",
    "# -------------------------\n",
    "KEEP_LAGS = sorted(list(KEEP_LAGS))\n",
    "KEEP_ROLLS = sorted(list(KEEP_ROLLS))\n",
    "\n",
    "def _static_cols(all_num_features):\n",
    "    stat = []\n",
    "    for c in all_num_features:\n",
    "        if c in (\"week_sin\", \"week_cos\"):\n",
    "            continue\n",
    "        if c.startswith(\"lag_\"):\n",
    "            continue\n",
    "        if c.startswith(\"roll_mean_\") or c.startswith(\"roll_std_\"):\n",
    "            continue\n",
    "        stat.append(c)\n",
    "    return stat\n",
    "\n",
    "STATIC_NUM = _static_cols(NUM_FEATURES)\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# ML RECURSIVE FORECAST (A/B/C only; OTHER excluded)\n",
    "# -------------------------\n",
    "def recursive_forecast_2026(\n",
    "    df_hist: pd.DataFrame,\n",
    "    models: dict,\n",
    "    cat_features=(\"country\",\"sku\"),\n",
    "    target_col=\"demand\",\n",
    "    num_features=None,\n",
    "    keep_lags=None,\n",
    "    keep_rolls=None,\n",
    "):\n",
    "    dfh = df_hist.copy()\n",
    "    dfh[\"week_start\"] = pd.to_datetime(dfh[\"week_start\"], errors=\"coerce\")\n",
    "    dfh = dfh[dfh[\"week_start\"].notna()].copy()\n",
    "    dfh[target_col] = pd.to_numeric(dfh[target_col], errors=\"coerce\").fillna(0.0).clip(lower=0.0)\n",
    "\n",
    "    dates_2026 = pd.date_range(\"2026-01-05\", \"2026-12-28\", freq=\"W-MON\")\n",
    "    out_rows = []\n",
    "\n",
    "    keys = [c for c in [\"country\",\"sku\"] if c in dfh.columns]\n",
    "\n",
    "    for (country, sku), g in dfh.groupby(keys, observed=True):\n",
    "        g = g.sort_values(\"week_start\")\n",
    "        y_hist = g[target_col].astype(float).tolist()\n",
    "\n",
    "        last = g.tail(1).iloc[0].to_dict()\n",
    "        product_name = last.get(\"product_name\", None)\n",
    "        segment = assign_segment(product_name)\n",
    "\n",
    "        # KLUCZOWE: OTHER NIE jest forecastowany ML tutaj\n",
    "        if segment == \"OTHER\":\n",
    "            continue\n",
    "\n",
    "        static_vals = {c: float(last.get(c, np.nan)) for c in STATIC_NUM if num_features and c in num_features}\n",
    "        for c in STATIC_NUM:\n",
    "            if num_features and c in num_features:\n",
    "                if not np.isfinite(static_vals.get(c, np.nan)):\n",
    "                    static_vals[c] = float(dfh[c].median()) if c in dfh.columns else 0.0\n",
    "\n",
    "        sigma = float(np.std(np.asarray(y_hist), ddof=0)) if len(y_hist) else 0.0\n",
    "        k = 1.28\n",
    "\n",
    "        for d in dates_2026:\n",
    "            row = {\n",
    "                \"country\": country,\n",
    "                \"sku\": sku,\n",
    "                \"week_start\": d,\n",
    "                \"product_name\": product_name,\n",
    "                \"segment\": segment,\n",
    "            }\n",
    "\n",
    "            for cf in cat_features:\n",
    "                if cf == \"country\":\n",
    "                    row[cf] = country\n",
    "                elif cf == \"sku\":\n",
    "                    row[cf] = sku\n",
    "\n",
    "            if num_features and \"week_sin\" in num_features:\n",
    "                row[\"week_sin\"] = float(np.sin(2*np.pi*int(d.isocalendar().week)/52.0))\n",
    "            if num_features and \"week_cos\" in num_features:\n",
    "                row[\"week_cos\"] = float(np.cos(2*np.pi*int(d.isocalendar().week)/52.0))\n",
    "\n",
    "            for c, v in static_vals.items():\n",
    "                row[c] = v\n",
    "\n",
    "            for l in keep_lags or []:\n",
    "                col = f\"lag_{l}\"\n",
    "                if num_features and col in num_features:\n",
    "                    row[col] = float(y_hist[-l]) if len(y_hist) >= l else float(np.mean(y_hist) if len(y_hist) else 0.0)\n",
    "\n",
    "            for w in keep_rolls or []:\n",
    "                mcol = f\"roll_mean_{w}\"\n",
    "                scol = f\"roll_std_{w}\"\n",
    "                tail = y_hist[-w:] if len(y_hist) >= w else y_hist[:]\n",
    "                if num_features and mcol in num_features:\n",
    "                    row[mcol] = float(np.mean(tail)) if len(tail) else 0.0\n",
    "                if num_features and scol in num_features:\n",
    "                    row[scol] = float(np.std(tail, ddof=0)) if len(tail) else 0.0\n",
    "\n",
    "            if num_features and \"is_outlier\" in num_features:\n",
    "                row[\"is_outlier\"] = 0.0\n",
    "\n",
    "            if num_features and \"is_zero\" in num_features:\n",
    "                lag1 = row.get(\"lag_1\", 0.0)\n",
    "                row[\"is_zero\"] = float(1.0 if lag1 == 0 else 0.0)\n",
    "\n",
    "            if num_features and \"weeks_since_nonzero\" in num_features:\n",
    "                ws = 0\n",
    "                for v in reversed(y_hist):\n",
    "                    if v == 0:\n",
    "                        ws += 1\n",
    "                    else:\n",
    "                        break\n",
    "                row[\"weeks_since_nonzero\"] = float(ws)\n",
    "\n",
    "            X_row = pd.DataFrame([row])\n",
    "\n",
    "            for cf in cat_features:\n",
    "                if cf in X_row.columns:\n",
    "                    X_row[cf] = X_row[cf].astype(\"category\")\n",
    "\n",
    "            X_row = safe_impute_num(X_row, num_features)\n",
    "            X = X_row[list(cat_features) + list(num_features)]\n",
    "\n",
    "            if segment == \"A\":\n",
    "                y_log = float(models[\"A\"].predict(X)[0])\n",
    "            elif segment == \"B\":\n",
    "                y_log = float(models[\"B\"].predict(X)[0])\n",
    "            else:  # segment == \"C\"\n",
    "                y_log = float(models[\"C\"].predict(X)[0])\n",
    "\n",
    "            y_pred = float(np.expm1(y_log))\n",
    "            y_pred = max(0.0, y_pred)\n",
    "\n",
    "            p10 = max(0.0, y_pred - k*sigma)\n",
    "            p90 = max(0.0, y_pred + k*sigma)\n",
    "\n",
    "            out_rows.append({\n",
    "                \"country\": country,\n",
    "                \"dc_id\": \"ALL\",\n",
    "                \"sku\": sku,\n",
    "                \"product_name\": product_name,\n",
    "                \"segment\": segment,\n",
    "                \"date\": d,\n",
    "                \"y_pred\": y_pred,\n",
    "                \"PI10\": p10,\n",
    "                \"PI90\": p90,\n",
    "                \"model_type\": \"ml_recursive\"\n",
    "            })\n",
    "\n",
    "            # recursive update\n",
    "            y_hist.append(y_pred)\n",
    "\n",
    "    return pd.DataFrame(out_rows)\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# MASTER_RAW + MISSING SERIES\n",
    "# -------------------------\n",
    "raw = pd.read_parquet(MASTER_RAW)\n",
    "raw[\"week_start\"] = pd.to_datetime(raw[\"week_start\"], errors=\"coerce\")\n",
    "raw = raw[raw[\"week_start\"].notna()].copy()\n",
    "raw[TARGET_RAW_FALLBACK] = pd.to_numeric(raw[TARGET_RAW_FALLBACK], errors=\"coerce\").fillna(0.0).clip(lower=0.0)\n",
    "\n",
    "all_series = raw[[\"country\",\"sku\",\"product_name\"]].drop_duplicates()\n",
    "ml_series = df_hist[[\"country\",\"sku\",\"product_name\"]].drop_duplicates()\n",
    "\n",
    "missing = all_series.merge(ml_series, on=[\"country\",\"sku\"], how=\"left\", indicator=True)\n",
    "missing = missing[missing[\"_merge\"]==\"left_only\"][[\"country\",\"sku\",\"product_name_x\"]].rename(columns={\"product_name_x\":\"product_name\"})\n",
    "\n",
    "print(\"Series missing in df_hist (features):\", missing.shape[0])\n",
    "\n",
    "df_fallback = fallback_forecast_2026(raw, missing)\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 1) ML FORECAST (A/B/C only)\n",
    "# -------------------------\n",
    "forecast_ml = recursive_forecast_2026(\n",
    "    df_hist=df_hist,\n",
    "    models=models,\n",
    "    cat_features=CAT_FEATURES,\n",
    "    target_col=TARGET_RAW,\n",
    "    num_features=NUM_FEATURES,\n",
    "    keep_lags=KEEP_LAGS,\n",
    "    keep_rolls=KEEP_ROLLS\n",
    ")\n",
    "\n",
    "print(\"forecast_ml rows:\", len(forecast_ml))\n",
    "print(\"forecast_ml model_type counts:\\n\", forecast_ml[\"model_type\"].value_counts().head(10))\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 2) FLATNESS FIX: płaskie ML -> baseline-best\n",
    "# -------------------------\n",
    "if not forecast_ml.empty:\n",
    "    flat_stats = (\n",
    "        forecast_ml.groupby([\"country\",\"sku\"], observed=True)[\"y_pred\"]\n",
    "        .agg([\"min\",\"max\",\"std\"]).reset_index()\n",
    "    )\n",
    "    FLAT_STD_EPS = 1e-6\n",
    "    flat_keys = set(map(tuple, flat_stats.loc[flat_stats[\"std\"].fillna(0.0) <= FLAT_STD_EPS, [\"country\",\"sku\"]].values))\n",
    "    print(\"Ile serii ML płaskich:\", len(flat_keys), \"na\", flat_stats.shape[0])\n",
    "\n",
    "    df_best_baseline_2026 = make_best_baseline_forecast_2026(raw, df_base)\n",
    "\n",
    "    idx = forecast_ml.set_index([\"country\",\"sku\"]).index\n",
    "    ml_ok = forecast_ml[~idx.isin(flat_keys)].copy()\n",
    "    bb_flat = df_best_baseline_2026[df_best_baseline_2026.set_index([\"country\",\"sku\"]).index.isin(flat_keys)].copy()\n",
    "\n",
    "    forecast_ml_fixed = pd.concat([ml_ok, bb_flat], ignore_index=True)\n",
    "else:\n",
    "    df_best_baseline_2026 = make_best_baseline_forecast_2026(raw, df_base)\n",
    "    forecast_ml_fixed = pd.DataFrame()\n",
    "\n",
    "if not forecast_ml_fixed.empty:\n",
    "    hist52 = (\n",
    "        df_hist.sort_values([\"country\",\"sku\",\"week_start\"])\n",
    "              .groupby([\"country\",\"sku\"], observed=True)\n",
    "              .tail(52)\n",
    "    )\n",
    "    hist_stats = (\n",
    "        hist52.groupby([\"country\",\"sku\"], observed=True)[TARGET_RAW]\n",
    "              .mean()\n",
    "              .reset_index(name=\"hist_mean_52\")\n",
    "    )\n",
    "\n",
    "    ml_stats = (\n",
    "        forecast_ml_fixed.groupby([\"country\",\"sku\"], observed=True)[\"y_pred\"]\n",
    "                        .mean()\n",
    "                        .reset_index(name=\"fc_mean\")\n",
    "    )\n",
    "\n",
    "    diag = ml_stats.merge(hist_stats, on=[\"country\",\"sku\"], how=\"left\")\n",
    "    diag[\"ratio\"] = diag[\"fc_mean\"] / diag[\"hist_mean_52\"].replace(0, np.nan)\n",
    "\n",
    "    HI = 1.8\n",
    "    LO = 0.55\n",
    "\n",
    "    bad = diag.loc[(diag[\"ratio\"] > HI) | (diag[\"ratio\"] < LO), [\"country\",\"sku\"]]\n",
    "    bad_keys = set(map(tuple, bad.values))\n",
    "    print(\"RATIO_GUARDRAIL bad series:\", len(bad_keys))\n",
    "\n",
    "    if bad_keys:\n",
    "        df_best_baseline_2026 = make_best_baseline_forecast_2026(raw, df_base)\n",
    "\n",
    "        idx = forecast_ml_fixed.set_index([\"country\",\"sku\"]).index\n",
    "        ml_ok = forecast_ml_fixed[~idx.isin(bad_keys)].copy()\n",
    "\n",
    "        bb_bad = df_best_baseline_2026[\n",
    "            df_best_baseline_2026.set_index([\"country\",\"sku\"]).index.isin(bad_keys)\n",
    "        ].copy()\n",
    "        bb_bad[\"model_type\"] = \"baseline_guardrail\"\n",
    "\n",
    "        forecast_ml_fixed = pd.concat([ml_ok, bb_bad], ignore_index=True)\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 3) OTHER: HYBRID forecast (non-flat)\n",
    "# -------------------------\n",
    "hist_keys = df_hist[[\"country\",\"sku\",\"product_name\"]].drop_duplicates().copy()\n",
    "hist_keys[\"segment\"] = hist_keys[\"product_name\"].astype(str).map(assign_segment)\n",
    "\n",
    "other_keys = hist_keys[hist_keys[\"segment\"] == \"OTHER\"][[\"country\",\"sku\"]].drop_duplicates()\n",
    "print(\"Series OTHER in df_hist:\", other_keys.shape[0])\n",
    "\n",
    "bb_other = pd.DataFrame()\n",
    "if other_keys.shape[0] > 0:\n",
    "    bb_other = other_forecast_2026_from_raw(raw, other_keys)\n",
    "\n",
    "print(\"bb_other rows:\", len(bb_other))\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 4) FINAL CONCAT: ML_fixed + baseline OTHER + fallback\n",
    "# -------------------------\n",
    "forecast_all = pd.concat([forecast_ml_fixed, bb_other, df_fallback], ignore_index=True)\n",
    "\n",
    "# --- FIX: kanoniczna nazwa GAZPACHO ---\n",
    "forecast_all[\"country\"] = forecast_all[\"country\"].astype(str)\n",
    "forecast_all[\"sku\"] = forecast_all[\"sku\"].astype(str)\n",
    "\n",
    "mask = (\n",
    "    (forecast_all[\"country\"] == \"Spain\") &\n",
    "    (forecast_all[\"sku\"] == \"00119-066-001\")\n",
    ")\n",
    "\n",
    "\n",
    "def canon_name_mode(s: pd.Series):\n",
    "    s = s.dropna().astype(str)\n",
    "    if s.empty:\n",
    "        return None\n",
    "    return s.value_counts().index[0]\n",
    "\n",
    "OVERRIDE = {\n",
    "    (\"Spain\", \"00119-066-001\"): \"GAZPACHO (17783-000)\"\n",
    "}\n",
    "\n",
    "# enforce canonical product_name (same rule as master_raw)\n",
    "dim_names = (\n",
    "    raw.groupby([\"country\",\"sku\"], as_index=False)[\"product_name\"]\n",
    "       .agg(product_name_canon=canon_name_mode)\n",
    ")\n",
    "dim_names[\"product_name_canon\"] = dim_names.apply(\n",
    "    lambda r: OVERRIDE.get((r[\"country\"], r[\"sku\"]), r[\"product_name_canon\"]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "forecast_all = forecast_all.drop(columns=[\"product_name\"], errors=\"ignore\")\n",
    "forecast_all = forecast_all.merge(dim_names, on=[\"country\",\"sku\"], how=\"left\")\n",
    "forecast_all = forecast_all.rename(columns={\"product_name_canon\":\"product_name\"})\n",
    "\n",
    "\n",
    "key = [\"country\",\"dc_id\",\"sku\",\"date\"]\n",
    "forecast_all = forecast_all.drop_duplicates(subset=key, keep=\"first\")\n",
    "forecast_all = forecast_all.sort_values([\"country\",\"dc_id\",\"sku\",\"date\"])\n",
    "\n",
    "forecast_all.to_parquet(OUT_FUTURE, index=False)\n",
    "print(\"Saved:\", OUT_FUTURE.resolve(), forecast_all.shape)\n",
    "print(\"model_type counts:\\n\", forecast_all[\"model_type\"].value_counts().head(20))\n",
    "\n",
    "print(\"Serie w forecast_all:\", forecast_all[[\"country\",\"dc_id\",\"sku\"]].drop_duplicates().shape[0])\n",
    "print(\"SKU w forecast_all:\", forecast_all[[\"country\",\"sku\"]].drop_duplicates().shape[0])\n",
    "print(\"Tygodnie 2026:\", forecast_all[\"date\"].nunique(), forecast_all[\"date\"].min(), forecast_all[\"date\"].max())\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# QUICK CHECKS (diagnostyka)\n",
    "# -------------------------\n",
    "fc = forecast_all.copy()\n",
    "fc[\"date\"] = pd.to_datetime(fc[\"date\"], errors=\"coerce\")\n",
    "\n",
    "print(\"\\n[CHECK] Duplicate rows on (country,dc_id,sku,date):\", int(fc.duplicated(subset=key).sum()))\n",
    "\n",
    "counts_csku_date = fc.groupby([\"country\",\"sku\",\"date\"], observed=True).size()\n",
    "max_per_date = int(counts_csku_date.max()) if len(counts_csku_date) else 0\n",
    "print(\"[CHECK] max rows per (country,sku,date):\", max_per_date)\n",
    "\n",
    "if \"PI10\" in fc.columns and \"PI90\" in fc.columns:\n",
    "    print(\"[CHECK] PI10 > PI90 rows:\", int((fc[\"PI10\"] > fc[\"PI90\"]).sum()))\n",
    "\n",
    "print(\"[CHECK] negative y_pred rows:\", int((fc[\"y_pred\"] < 0).sum()))\n",
    "print(\"[CHECK] share of y_pred == 0:\", float((fc[\"y_pred\"] == 0).mean()))\n",
    "\n",
    "# flatness per series (country,dc_id,sku)\n",
    "stat = (\n",
    "    fc.groupby([\"country\",\"dc_id\",\"sku\"], observed=True)[\"y_pred\"]\n",
    "    .agg(y_min=\"min\", y_max=\"max\", y_mean=\"mean\", y_std=\"std\")\n",
    "    .reset_index()\n",
    ")\n",
    "flat_by_std = stat[\"y_std\"].fillna(0.0) <= 1e-6\n",
    "print(\"[CHECK] flat series by std<=1e-6:\", int(flat_by_std.sum()), \"/\", len(stat))\n",
    "\n",
    "print(\"\\nDONE.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "e01aa81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [country, sku, model_type, std, n, is_flat]\n",
      "Index: []\n",
      "\n",
      "Flat ML: 0\n"
     ]
    }
   ],
   "source": [
    "flat = (forecast_all.groupby([\"country\",\"sku\",\"model_type\"])[\"y_pred\"]\n",
    "        .agg(std=\"std\", n=\"size\").reset_index())\n",
    "flat[\"is_flat\"] = flat[\"std\"].fillna(0.0) <= 1e-6\n",
    "\n",
    "print(flat[flat[\"is_flat\"]].sort_values([\"model_type\",\"country\",\"sku\"]))\n",
    "print(\"\\nFlat ML:\", flat[(flat[\"is_flat\"]) & (flat[\"model_type\"]==\"ml_recursive\")].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "d4d5a036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     country            sku      fc_mean  hist_mean_52  hist_last     ratio\n",
      "13     Spain  00023-189-000    27.517121    266.309615     96.936  0.103328\n",
      "7   Portugal  00041-097-000     7.861929     27.076923     12.000  0.290355\n",
      "10   Romania  05243-115-000    69.486966    217.512865    181.000  0.319461\n",
      "6   Portugal  00012-619-000  3320.464326   7668.401923   2910.000  0.433006\n",
      "8    Romania  00012-432-000   516.344935   1061.134615    638.000  0.486597\n",
      "17    Sweden  00295-629-000   119.721763    224.615385    259.000  0.533008\n",
      "9    Romania  00077-010-000   499.392370    632.811538    357.000  0.789164\n",
      "5     Poland  62170-027-000    41.568539     46.250000     27.000  0.898779\n",
      "1    Germany  00019-003-003  8200.215488   8682.346154   5571.000  0.944470\n",
      "2     Poland  02589-489-000  9111.899331   9232.557692   5821.000  0.986931\n",
      "    country            sku      fc_mean  hist_mean_52  hist_last     ratio\n",
      "16   Sweden  00011-294-000  3060.407259   2873.807692     2120.0  1.064931\n",
      "15    Spain  04592-030-000  1549.375574   1541.817308      635.0  1.004902\n",
      "19   Sweden     75-072-000  2512.879573   2503.615385     2528.0  1.003700\n",
      "11  Romania  07808-016-000     2.198854      2.211538        2.0  0.994265\n",
      "2    Poland  02589-489-000  9111.899331   9232.557692     5821.0  0.986931\n",
      "1   Germany  00019-003-003  8200.215488   8682.346154     5571.0  0.944470\n",
      "5    Poland  62170-027-000    41.568539     46.250000       27.0  0.898779\n",
      "9   Romania  00077-010-000   499.392370    632.811538      357.0  0.789164\n",
      "17   Sweden  00295-629-000   119.721763    224.615385      259.0  0.533008\n",
      "8   Romania  00012-432-000   516.344935   1061.134615      638.0  0.486597\n"
     ]
    }
   ],
   "source": [
    "hist52 = (\n",
    "    df_hist.sort_values([\"country\",\"sku\",\"week_start\"])\n",
    "    .groupby([\"country\",\"sku\"], observed=True)\n",
    "    .tail(52)\n",
    ")\n",
    "\n",
    "hist_stats = (hist52.groupby([\"country\",\"sku\"], observed=True)[TARGET_RAW]\n",
    "              .agg(hist_mean_52=\"mean\", hist_last=\"last\")\n",
    "              .reset_index())\n",
    "\n",
    "fc_stats = (forecast_all.groupby([\"country\",\"sku\"], observed=True)[\"y_pred\"]\n",
    "            .agg(fc_mean=\"mean\").reset_index())\n",
    "\n",
    "diag = fc_stats.merge(hist_stats, on=[\"country\",\"sku\"], how=\"left\")\n",
    "diag[\"ratio\"] = diag[\"fc_mean\"] / diag[\"hist_mean_52\"].replace(0, np.nan)\n",
    "\n",
    "print(diag.sort_values(\"ratio\").head(10))\n",
    "print(diag.sort_values(\"ratio\", ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "72d7efaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:\\Users\\48573\\Desktop\\Programy_rozwój\\TopYoung100\\HAVI\\data\\master_model_ready.parquet\n",
      "Rows: 18966 Series: 20\n",
      "Date range: 2018-12-31 00:00:00 -> 2025-11-03 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"data\")\n",
    "\n",
    "RAW_PATH = DATA_DIR / \"master_raw.parquet\"\n",
    "OUT_PATH = DATA_DIR / \"master_model_ready.parquet\"\n",
    "\n",
    "raw = pd.read_parquet(RAW_PATH)\n",
    "\n",
    "# wymagane minimum do dashboardu\n",
    "raw[\"week_start\"] = pd.to_datetime(raw[\"week_start\"], errors=\"coerce\")\n",
    "raw = raw[raw[\"week_start\"].notna()].copy()\n",
    "\n",
    "# demand_raw musi istnieć\n",
    "if \"demand_raw\" not in raw.columns:\n",
    "    raise ValueError(\"master_raw.parquet musi mieć kolumnę demand_raw\")\n",
    "\n",
    "raw[\"demand_raw\"] = pd.to_numeric(raw[\"demand_raw\"], errors=\"coerce\").fillna(0.0)\n",
    "\n",
    "# ujednolicenie do formatu dashboardu\n",
    "out = raw.rename(columns={\"week_start\": \"date\"}).copy()\n",
    "\n",
    "# kolumny, które dashboard lubi mieć (część jest opcjonalna)\n",
    "if \"product_name\" not in out.columns:\n",
    "    out[\"product_name\"] = out[\"sku\"].astype(str)\n",
    "if \"dc_id\" not in out.columns:\n",
    "    out[\"dc_id\"] = \"ALL\"\n",
    "\n",
    "# minimalny zestaw + kilka przydatnych\n",
    "keep = [c for c in [\"country\", \"sku\", \"product_name\", \"dc_id\", \"date\", \"demand_raw\"] if c in out.columns]\n",
    "out = out[keep].sort_values([\"country\", \"sku\", \"date\"])\n",
    "\n",
    "out.to_parquet(OUT_PATH, index=False)\n",
    "\n",
    "print(\"Saved:\", OUT_PATH.resolve())\n",
    "print(\"Rows:\", len(out), \"Series:\", out[[\"country\",\"sku\"]].drop_duplicates().shape[0])\n",
    "print(\"Date range:\", out[\"date\"].min(), \"->\", out[\"date\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "42432a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forecast_future.parquet -> OK | C:\\Users\\48573\\Desktop\\Programy_rozwój\\TopYoung100\\HAVI\\data\\forecast_future.parquet\n",
      "master_model_ready.parquet -> OK | C:\\Users\\48573\\Desktop\\Programy_rozwój\\TopYoung100\\HAVI\\data\\master_model_ready.parquet\n",
      "forecast_backtest.parquet -> OK | C:\\Users\\48573\\Desktop\\Programy_rozwój\\TopYoung100\\HAVI\\data\\forecast_backtest.parquet\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"data\")\n",
    "need = [\n",
    "    \"forecast_future.parquet\",\n",
    "    \"master_model_ready.parquet\",   # historia\n",
    "    \"forecast_backtest.parquet\",    # jeśli chcesz backtest tab\n",
    "]\n",
    "\n",
    "for f in need:\n",
    "    p = DATA_DIR / f\n",
    "    print(f, \"->\", \"OK\" if p.exists() else \"BRAK\", \"|\", p.resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "2d2f163d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flat series count: 0 / 20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>sku</th>\n",
       "      <th>model_type</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>n</th>\n",
       "      <th>is_flat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Romania</td>\n",
       "      <td>07808-016-000</td>\n",
       "      <td>ml_recursive</td>\n",
       "      <td>0.532951</td>\n",
       "      <td>1.267461</td>\n",
       "      <td>3.205173</td>\n",
       "      <td>52</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Romania</td>\n",
       "      <td>76518-000-000</td>\n",
       "      <td>other_hybrid</td>\n",
       "      <td>1.460248</td>\n",
       "      <td>0.809310</td>\n",
       "      <td>9.786552</td>\n",
       "      <td>52</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Portugal</td>\n",
       "      <td>00041-097-000</td>\n",
       "      <td>other_hybrid</td>\n",
       "      <td>2.927641</td>\n",
       "      <td>3.416812</td>\n",
       "      <td>15.462899</td>\n",
       "      <td>52</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Poland</td>\n",
       "      <td>62170-027-000</td>\n",
       "      <td>ml_recursive</td>\n",
       "      <td>6.868571</td>\n",
       "      <td>27.254284</td>\n",
       "      <td>69.558327</td>\n",
       "      <td>52</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Poland</td>\n",
       "      <td>16333-000-000</td>\n",
       "      <td>other_hybrid</td>\n",
       "      <td>7.262334</td>\n",
       "      <td>13.199144</td>\n",
       "      <td>49.010680</td>\n",
       "      <td>52</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>00295-629-000</td>\n",
       "      <td>other_hybrid</td>\n",
       "      <td>10.970135</td>\n",
       "      <td>99.735874</td>\n",
       "      <td>143.428161</td>\n",
       "      <td>52</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Spain</td>\n",
       "      <td>00023-189-000</td>\n",
       "      <td>other_hybrid</td>\n",
       "      <td>15.445286</td>\n",
       "      <td>7.780235</td>\n",
       "      <td>61.716255</td>\n",
       "      <td>52</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Romania</td>\n",
       "      <td>00012-432-000</td>\n",
       "      <td>ml_recursive</td>\n",
       "      <td>18.552101</td>\n",
       "      <td>470.418816</td>\n",
       "      <td>544.334768</td>\n",
       "      <td>52</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>00397-117-000</td>\n",
       "      <td>other_hybrid</td>\n",
       "      <td>21.220021</td>\n",
       "      <td>136.365928</td>\n",
       "      <td>233.335244</td>\n",
       "      <td>52</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Romania</td>\n",
       "      <td>05243-115-000</td>\n",
       "      <td>other_hybrid</td>\n",
       "      <td>41.444410</td>\n",
       "      <td>17.860690</td>\n",
       "      <td>173.561379</td>\n",
       "      <td>52</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Romania</td>\n",
       "      <td>00077-010-000</td>\n",
       "      <td>ml_recursive</td>\n",
       "      <td>59.325706</td>\n",
       "      <td>200.454958</td>\n",
       "      <td>546.724873</td>\n",
       "      <td>52</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Spain</td>\n",
       "      <td>00119-066-001</td>\n",
       "      <td>other_hybrid</td>\n",
       "      <td>124.463434</td>\n",
       "      <td>54.615491</td>\n",
       "      <td>480.080231</td>\n",
       "      <td>52</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Poland</td>\n",
       "      <td>05243-022-000</td>\n",
       "      <td>other_hybrid</td>\n",
       "      <td>143.387450</td>\n",
       "      <td>219.834958</td>\n",
       "      <td>811.328578</td>\n",
       "      <td>52</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Spain</td>\n",
       "      <td>04592-030-000</td>\n",
       "      <td>ml_recursive</td>\n",
       "      <td>170.098024</td>\n",
       "      <td>1138.049996</td>\n",
       "      <td>1808.436296</td>\n",
       "      <td>52</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>75-072-000</td>\n",
       "      <td>ml_recursive</td>\n",
       "      <td>265.730868</td>\n",
       "      <td>2149.576578</td>\n",
       "      <td>3161.880183</td>\n",
       "      <td>52</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Poland</td>\n",
       "      <td>02589-489-000</td>\n",
       "      <td>ml_recursive</td>\n",
       "      <td>401.316536</td>\n",
       "      <td>8135.922251</td>\n",
       "      <td>9892.266811</td>\n",
       "      <td>52</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>00011-294-000</td>\n",
       "      <td>ml_recursive</td>\n",
       "      <td>410.605175</td>\n",
       "      <td>2034.595135</td>\n",
       "      <td>3900.475695</td>\n",
       "      <td>52</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Germany</td>\n",
       "      <td>00019-003-003</td>\n",
       "      <td>ml_recursive</td>\n",
       "      <td>542.550197</td>\n",
       "      <td>6156.568353</td>\n",
       "      <td>9071.467404</td>\n",
       "      <td>52</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Portugal</td>\n",
       "      <td>00012-619-000</td>\n",
       "      <td>other_hybrid</td>\n",
       "      <td>1162.277480</td>\n",
       "      <td>924.917073</td>\n",
       "      <td>5429.976585</td>\n",
       "      <td>52</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Germany</td>\n",
       "      <td>00004-807-019</td>\n",
       "      <td>other_hybrid</td>\n",
       "      <td>1737.664386</td>\n",
       "      <td>2065.788868</td>\n",
       "      <td>7536.570189</td>\n",
       "      <td>52</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     country            sku    model_type          std          min  \\\n",
       "11   Romania  07808-016-000  ml_recursive     0.532951     1.267461   \n",
       "12   Romania  76518-000-000  other_hybrid     1.460248     0.809310   \n",
       "7   Portugal  00041-097-000  other_hybrid     2.927641     3.416812   \n",
       "5     Poland  62170-027-000  ml_recursive     6.868571    27.254284   \n",
       "4     Poland  16333-000-000  other_hybrid     7.262334    13.199144   \n",
       "17    Sweden  00295-629-000  other_hybrid    10.970135    99.735874   \n",
       "13     Spain  00023-189-000  other_hybrid    15.445286     7.780235   \n",
       "8    Romania  00012-432-000  ml_recursive    18.552101   470.418816   \n",
       "18    Sweden  00397-117-000  other_hybrid    21.220021   136.365928   \n",
       "10   Romania  05243-115-000  other_hybrid    41.444410    17.860690   \n",
       "9    Romania  00077-010-000  ml_recursive    59.325706   200.454958   \n",
       "14     Spain  00119-066-001  other_hybrid   124.463434    54.615491   \n",
       "3     Poland  05243-022-000  other_hybrid   143.387450   219.834958   \n",
       "15     Spain  04592-030-000  ml_recursive   170.098024  1138.049996   \n",
       "19    Sweden     75-072-000  ml_recursive   265.730868  2149.576578   \n",
       "2     Poland  02589-489-000  ml_recursive   401.316536  8135.922251   \n",
       "16    Sweden  00011-294-000  ml_recursive   410.605175  2034.595135   \n",
       "1    Germany  00019-003-003  ml_recursive   542.550197  6156.568353   \n",
       "6   Portugal  00012-619-000  other_hybrid  1162.277480   924.917073   \n",
       "0    Germany  00004-807-019  other_hybrid  1737.664386  2065.788868   \n",
       "\n",
       "            max   n  is_flat  \n",
       "11     3.205173  52    False  \n",
       "12     9.786552  52    False  \n",
       "7     15.462899  52    False  \n",
       "5     69.558327  52    False  \n",
       "4     49.010680  52    False  \n",
       "17   143.428161  52    False  \n",
       "13    61.716255  52    False  \n",
       "8    544.334768  52    False  \n",
       "18   233.335244  52    False  \n",
       "10   173.561379  52    False  \n",
       "9    546.724873  52    False  \n",
       "14   480.080231  52    False  \n",
       "3    811.328578  52    False  \n",
       "15  1808.436296  52    False  \n",
       "19  3161.880183  52    False  \n",
       "2   9892.266811  52    False  \n",
       "16  3900.475695  52    False  \n",
       "1   9071.467404  52    False  \n",
       "6   5429.976585  52    False  \n",
       "0   7536.570189  52    False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- DIAGNOSTYKA: które serie są płaskie i jaki mają model_type ---\n",
    "fc = forecast_all.copy()\n",
    "\n",
    "flat = (\n",
    "    fc.groupby([\"country\",\"sku\",\"model_type\"], observed=True)[\"y_pred\"]\n",
    "      .agg(std=\"std\", min=\"min\", max=\"max\", n=\"size\")\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "flat[\"is_flat\"] = flat[\"std\"].fillna(0.0) <= 1e-6\n",
    "\n",
    "print(\"Flat series count:\", flat[\"is_flat\"].sum(), \"/\", len(flat))\n",
    "display(flat.sort_values([\"is_flat\",\"std\"], ascending=[False, True]).head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "8a8c7bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flat ML series: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>sku</th>\n",
       "      <th>model_type</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>n</th>\n",
       "      <th>is_flat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [country, sku, model_type, std, min, max, n, is_flat]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Czy ML też bywa płaski? ---\n",
    "flat_ml = flat[(flat[\"is_flat\"]) & (flat[\"model_type\"] == \"ml_recursive\")]\n",
    "print(\"Flat ML series:\", len(flat_ml))\n",
    "display(flat_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "4c524630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP najniższe ratio (forecast za mały vs historia):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>sku</th>\n",
       "      <th>fc_mean</th>\n",
       "      <th>fc_min</th>\n",
       "      <th>fc_max</th>\n",
       "      <th>fc_std</th>\n",
       "      <th>hist_mean_52</th>\n",
       "      <th>hist_last</th>\n",
       "      <th>ratio_fc_to_hist_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Romania</td>\n",
       "      <td>00012-432-000</td>\n",
       "      <td>516.344935</td>\n",
       "      <td>470.418816</td>\n",
       "      <td>544.334768</td>\n",
       "      <td>18.552101</td>\n",
       "      <td>1061.134615</td>\n",
       "      <td>638.0</td>\n",
       "      <td>0.486597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Romania</td>\n",
       "      <td>00077-010-000</td>\n",
       "      <td>499.392370</td>\n",
       "      <td>200.454958</td>\n",
       "      <td>546.724873</td>\n",
       "      <td>59.325706</td>\n",
       "      <td>632.811538</td>\n",
       "      <td>357.0</td>\n",
       "      <td>0.789164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Poland</td>\n",
       "      <td>62170-027-000</td>\n",
       "      <td>41.568539</td>\n",
       "      <td>27.254284</td>\n",
       "      <td>69.558327</td>\n",
       "      <td>6.868571</td>\n",
       "      <td>46.250000</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.898779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Germany</td>\n",
       "      <td>00019-003-003</td>\n",
       "      <td>8200.215488</td>\n",
       "      <td>6156.568353</td>\n",
       "      <td>9071.467404</td>\n",
       "      <td>542.550197</td>\n",
       "      <td>8682.346154</td>\n",
       "      <td>5571.0</td>\n",
       "      <td>0.944470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Poland</td>\n",
       "      <td>02589-489-000</td>\n",
       "      <td>9111.899331</td>\n",
       "      <td>8135.922251</td>\n",
       "      <td>9892.266811</td>\n",
       "      <td>401.316536</td>\n",
       "      <td>9232.557692</td>\n",
       "      <td>5821.0</td>\n",
       "      <td>0.986931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Romania</td>\n",
       "      <td>07808-016-000</td>\n",
       "      <td>2.198854</td>\n",
       "      <td>1.267461</td>\n",
       "      <td>3.205173</td>\n",
       "      <td>0.532951</td>\n",
       "      <td>2.211538</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.994265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>75-072-000</td>\n",
       "      <td>2512.879573</td>\n",
       "      <td>2149.576578</td>\n",
       "      <td>3161.880183</td>\n",
       "      <td>265.730868</td>\n",
       "      <td>2503.615385</td>\n",
       "      <td>2528.0</td>\n",
       "      <td>1.003700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Spain</td>\n",
       "      <td>04592-030-000</td>\n",
       "      <td>1549.375574</td>\n",
       "      <td>1138.049996</td>\n",
       "      <td>1808.436296</td>\n",
       "      <td>170.098024</td>\n",
       "      <td>1541.817308</td>\n",
       "      <td>635.0</td>\n",
       "      <td>1.004902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>00011-294-000</td>\n",
       "      <td>3060.407259</td>\n",
       "      <td>2034.595135</td>\n",
       "      <td>3900.475695</td>\n",
       "      <td>410.605175</td>\n",
       "      <td>2873.807692</td>\n",
       "      <td>2120.0</td>\n",
       "      <td>1.064931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country            sku      fc_mean       fc_min       fc_max      fc_std  \\\n",
       "3  Romania  00012-432-000   516.344935   470.418816   544.334768   18.552101   \n",
       "4  Romania  00077-010-000   499.392370   200.454958   546.724873   59.325706   \n",
       "2   Poland  62170-027-000    41.568539    27.254284    69.558327    6.868571   \n",
       "0  Germany  00019-003-003  8200.215488  6156.568353  9071.467404  542.550197   \n",
       "1   Poland  02589-489-000  9111.899331  8135.922251  9892.266811  401.316536   \n",
       "5  Romania  07808-016-000     2.198854     1.267461     3.205173    0.532951   \n",
       "8   Sweden     75-072-000  2512.879573  2149.576578  3161.880183  265.730868   \n",
       "6    Spain  04592-030-000  1549.375574  1138.049996  1808.436296  170.098024   \n",
       "7   Sweden  00011-294-000  3060.407259  2034.595135  3900.475695  410.605175   \n",
       "\n",
       "   hist_mean_52  hist_last  ratio_fc_to_hist_mean  \n",
       "3   1061.134615      638.0               0.486597  \n",
       "4    632.811538      357.0               0.789164  \n",
       "2     46.250000       27.0               0.898779  \n",
       "0   8682.346154     5571.0               0.944470  \n",
       "1   9232.557692     5821.0               0.986931  \n",
       "5      2.211538        2.0               0.994265  \n",
       "8   2503.615385     2528.0               1.003700  \n",
       "6   1541.817308      635.0               1.004902  \n",
       "7   2873.807692     2120.0               1.064931  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP najwyższe ratio (forecast za duży vs historia):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>sku</th>\n",
       "      <th>fc_mean</th>\n",
       "      <th>fc_min</th>\n",
       "      <th>fc_max</th>\n",
       "      <th>fc_std</th>\n",
       "      <th>hist_mean_52</th>\n",
       "      <th>hist_last</th>\n",
       "      <th>ratio_fc_to_hist_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>00011-294-000</td>\n",
       "      <td>3060.407259</td>\n",
       "      <td>2034.595135</td>\n",
       "      <td>3900.475695</td>\n",
       "      <td>410.605175</td>\n",
       "      <td>2873.807692</td>\n",
       "      <td>2120.0</td>\n",
       "      <td>1.064931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Spain</td>\n",
       "      <td>04592-030-000</td>\n",
       "      <td>1549.375574</td>\n",
       "      <td>1138.049996</td>\n",
       "      <td>1808.436296</td>\n",
       "      <td>170.098024</td>\n",
       "      <td>1541.817308</td>\n",
       "      <td>635.0</td>\n",
       "      <td>1.004902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>75-072-000</td>\n",
       "      <td>2512.879573</td>\n",
       "      <td>2149.576578</td>\n",
       "      <td>3161.880183</td>\n",
       "      <td>265.730868</td>\n",
       "      <td>2503.615385</td>\n",
       "      <td>2528.0</td>\n",
       "      <td>1.003700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Romania</td>\n",
       "      <td>07808-016-000</td>\n",
       "      <td>2.198854</td>\n",
       "      <td>1.267461</td>\n",
       "      <td>3.205173</td>\n",
       "      <td>0.532951</td>\n",
       "      <td>2.211538</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.994265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Poland</td>\n",
       "      <td>02589-489-000</td>\n",
       "      <td>9111.899331</td>\n",
       "      <td>8135.922251</td>\n",
       "      <td>9892.266811</td>\n",
       "      <td>401.316536</td>\n",
       "      <td>9232.557692</td>\n",
       "      <td>5821.0</td>\n",
       "      <td>0.986931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Germany</td>\n",
       "      <td>00019-003-003</td>\n",
       "      <td>8200.215488</td>\n",
       "      <td>6156.568353</td>\n",
       "      <td>9071.467404</td>\n",
       "      <td>542.550197</td>\n",
       "      <td>8682.346154</td>\n",
       "      <td>5571.0</td>\n",
       "      <td>0.944470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Poland</td>\n",
       "      <td>62170-027-000</td>\n",
       "      <td>41.568539</td>\n",
       "      <td>27.254284</td>\n",
       "      <td>69.558327</td>\n",
       "      <td>6.868571</td>\n",
       "      <td>46.250000</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.898779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Romania</td>\n",
       "      <td>00077-010-000</td>\n",
       "      <td>499.392370</td>\n",
       "      <td>200.454958</td>\n",
       "      <td>546.724873</td>\n",
       "      <td>59.325706</td>\n",
       "      <td>632.811538</td>\n",
       "      <td>357.0</td>\n",
       "      <td>0.789164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Romania</td>\n",
       "      <td>00012-432-000</td>\n",
       "      <td>516.344935</td>\n",
       "      <td>470.418816</td>\n",
       "      <td>544.334768</td>\n",
       "      <td>18.552101</td>\n",
       "      <td>1061.134615</td>\n",
       "      <td>638.0</td>\n",
       "      <td>0.486597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country            sku      fc_mean       fc_min       fc_max      fc_std  \\\n",
       "7   Sweden  00011-294-000  3060.407259  2034.595135  3900.475695  410.605175   \n",
       "6    Spain  04592-030-000  1549.375574  1138.049996  1808.436296  170.098024   \n",
       "8   Sweden     75-072-000  2512.879573  2149.576578  3161.880183  265.730868   \n",
       "5  Romania  07808-016-000     2.198854     1.267461     3.205173    0.532951   \n",
       "1   Poland  02589-489-000  9111.899331  8135.922251  9892.266811  401.316536   \n",
       "0  Germany  00019-003-003  8200.215488  6156.568353  9071.467404  542.550197   \n",
       "2   Poland  62170-027-000    41.568539    27.254284    69.558327    6.868571   \n",
       "4  Romania  00077-010-000   499.392370   200.454958   546.724873   59.325706   \n",
       "3  Romania  00012-432-000   516.344935   470.418816   544.334768   18.552101   \n",
       "\n",
       "   hist_mean_52  hist_last  ratio_fc_to_hist_mean  \n",
       "7   2873.807692     2120.0               1.064931  \n",
       "6   1541.817308      635.0               1.004902  \n",
       "8   2503.615385     2528.0               1.003700  \n",
       "5      2.211538        2.0               0.994265  \n",
       "1   9232.557692     5821.0               0.986931  \n",
       "0   8682.346154     5571.0               0.944470  \n",
       "2     46.250000       27.0               0.898779  \n",
       "4    632.811538      357.0               0.789164  \n",
       "3   1061.134615      638.0               0.486597  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === QUICK DIAG: skala forecast vs historia (ostatnie 52 tyg.) ===\n",
    "hist52 = (\n",
    "    df_hist.sort_values([\"country\",\"sku\",\"week_start\"])\n",
    "    .groupby([\"country\",\"sku\"], observed=True)\n",
    "    .tail(52)\n",
    ")\n",
    "\n",
    "hist_stats = (hist52.groupby([\"country\",\"sku\"], observed=True)[TARGET_RAW]\n",
    "              .agg(hist_mean_52=\"mean\", hist_last=\"last\")\n",
    "              .reset_index())\n",
    "\n",
    "fc_stats = (forecast_ml.groupby([\"country\",\"sku\"], observed=True)[\"y_pred\"]\n",
    "            .agg(fc_mean=\"mean\", fc_min=\"min\", fc_max=\"max\", fc_std=\"std\")\n",
    "            .reset_index())\n",
    "\n",
    "diag = fc_stats.merge(hist_stats, on=[\"country\",\"sku\"], how=\"left\")\n",
    "diag[\"ratio_fc_to_hist_mean\"] = diag[\"fc_mean\"] / diag[\"hist_mean_52\"].replace(0, np.nan)\n",
    "\n",
    "print(\"TOP najniższe ratio (forecast za mały vs historia):\")\n",
    "display(diag.sort_values(\"ratio_fc_to_hist_mean\", ascending=True).head(10))\n",
    "\n",
    "print(\"TOP najwyższe ratio (forecast za duży vs historia):\")\n",
    "display(diag.sort_values(\"ratio_fc_to_hist_mean\", ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "ffc50467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== features_level_a ===\n",
      "rows: 129 date range: 2023-05-22 00:00:00 -> 2025-11-03 00:00:00\n",
      "last 5 y: [31.0, 23.0, 17.0, 37.0, 27.0]\n",
      "mean: 56.26201550387597 median: 40.0 max: 195.0\n",
      "\n",
      "=== master_raw ===\n",
      "rows: 542 date range: 2022-05-23 00:00:00 -> 2025-11-03 00:00:00\n",
      "last 5 y: [12.0, 9.0, 8.0, 9.0, 10.0]\n",
      "mean: 21.689298892988926 median: 16.0 max: 103.0\n",
      "\n",
      "=== master_model_ready ===\n",
      "rows: 542 date range: 2022-05-23 00:00:00 -> 2025-11-03 00:00:00\n",
      "last 5 y: [12.0, 16.0, 8.0, 9.0, 10.0]\n",
      "mean: 21.689298892988926 median: 16.0 max: 103.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# wybierz problematyczny przykład:\n",
    "C = \"Poland\"\n",
    "SKU = \"62170-027-000\"   # Chipsy PAPRYKA\n",
    "\n",
    "# df_hist = features_level_a.parquet (masz to w 09 jako df_hist)\n",
    "# raw = master_raw.parquet (masz to w 09 jako raw)\n",
    "# albo jeśli chcesz porównać do master_model_ready.parquet używanego w Streamlit:\n",
    "m = pd.read_parquet(\"data/master_model_ready.parquet\")\n",
    "\n",
    "a = df_hist[(df_hist[\"country\"].astype(str)==C) & (df_hist[\"sku\"].astype(str)==SKU)].copy()\n",
    "b = raw[(raw[\"country\"].astype(str)==C) & (raw[\"sku\"].astype(str)==SKU)].copy()\n",
    "c = m[(m[\"country\"].astype(str)==C) & (m[\"sku\"].astype(str)==SKU)].copy()\n",
    "\n",
    "for name, g, ycol, dcol in [\n",
    "    (\"features_level_a\", a, \"demand\", \"week_start\"),\n",
    "    (\"master_raw\",       b, \"demand_raw\", \"week_start\"),\n",
    "    (\"master_model_ready\", c, \"demand_raw\", \"date\" if \"date\" in c.columns else \"week_start\"),\n",
    "]:\n",
    "    if g.empty:\n",
    "        print(name, \"EMPTY\")\n",
    "        continue\n",
    "    g[dcol] = pd.to_datetime(g[dcol], errors=\"coerce\")\n",
    "    g = g[g[dcol].notna()].sort_values(dcol)\n",
    "    y = pd.to_numeric(g[ycol], errors=\"coerce\").fillna(0.0)\n",
    "    print(\"\\n===\", name, \"===\")\n",
    "    print(\"rows:\", len(g), \"date range:\", g[dcol].min(), \"->\", g[dcol].max())\n",
    "    print(\"last 5 y:\", y.tail(5).tolist())\n",
    "    print(\"mean:\", float(y.mean()), \"median:\", float(y.median()), \"max:\", float(y.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "a9ea312e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     country            sku       y_pred  last_feat_demand  \\\n",
      "10   Romania  05243-115-000    55.930345           181.000   \n",
      "7   Portugal  00041-097-000     5.309855            12.000   \n",
      "17    Sweden  00295-629-000   125.965291           259.000   \n",
      "9    Romania  00077-010-000   200.454958           357.000   \n",
      "13     Spain  00023-189-000    61.716255            96.936   \n",
      "6   Portugal  00012-619-000  2121.742439          2910.000   \n",
      "8    Romania  00012-432-000   508.406974           638.000   \n",
      "19    Sweden     75-072-000  2350.886823          2528.000   \n",
      "11   Romania  07808-016-000     2.173945             2.000   \n",
      "16    Sweden  00011-294-000  2486.219864          2120.000   \n",
      "1    Germany  00019-003-003  7332.782283          5571.000   \n",
      "2     Poland  02589-489-000  8300.907959          5821.000   \n",
      "5     Poland  62170-027-000    45.486956            27.000   \n",
      "15     Spain  04592-030-000  1419.798037           635.000   \n",
      "0    Germany  00004-807-019  2173.760566               NaN   \n",
      "3     Poland  05243-022-000   693.891099               NaN   \n",
      "4     Poland  16333-000-000    23.971537               NaN   \n",
      "12   Romania  76518-000-000     1.438276               NaN   \n",
      "14     Spain  00119-066-001   220.125010               NaN   \n",
      "18    Sweden  00397-117-000   177.147687               NaN   \n",
      "\n",
      "    ratio_pred_to_feat_last    model_type  \n",
      "10                 0.309007  other_hybrid  \n",
      "7                  0.442488  other_hybrid  \n",
      "17                 0.486352  other_hybrid  \n",
      "9                  0.561498  ml_recursive  \n",
      "13                 0.636670  other_hybrid  \n",
      "6                  0.729121  other_hybrid  \n",
      "8                  0.796876  ml_recursive  \n",
      "19                 0.929939  ml_recursive  \n",
      "11                 1.086972  ml_recursive  \n",
      "16                 1.172745  ml_recursive  \n",
      "1                  1.316242  ml_recursive  \n",
      "2                  1.426028  ml_recursive  \n",
      "5                  1.684702  ml_recursive  \n",
      "15                 2.235902  ml_recursive  \n",
      "0                       NaN  other_hybrid  \n",
      "3                       NaN  other_hybrid  \n",
      "4                       NaN  other_hybrid  \n",
      "12                      NaN  other_hybrid  \n",
      "14                      NaN  other_hybrid  \n",
      "18                      NaN  other_hybrid  \n"
     ]
    }
   ],
   "source": [
    "fc = pd.read_parquet(\"data/forecast_future.parquet\")\n",
    "fc[\"date\"] = pd.to_datetime(fc[\"date\"], errors=\"coerce\")\n",
    "\n",
    "# bierzemy pierwszy tydzień forecastu\n",
    "fc1 = fc[fc[\"date\"] == fc[\"date\"].min()].copy()\n",
    "\n",
    "# last history from features_level_a:\n",
    "last_feat = (df_hist.sort_values(\"week_start\")\n",
    "             .groupby([\"country\",\"sku\"], as_index=False)\n",
    "             .tail(1)[[\"country\",\"sku\",\"week_start\",\"demand\"]]\n",
    "             .rename(columns={\"week_start\":\"last_feat_date\",\"demand\":\"last_feat_demand\"}))\n",
    "\n",
    "tmp = fc1.merge(last_feat, on=[\"country\",\"sku\"], how=\"left\")\n",
    "tmp[\"y_pred\"] = pd.to_numeric(tmp[\"y_pred\"], errors=\"coerce\")\n",
    "tmp[\"ratio_pred_to_feat_last\"] = tmp[\"y_pred\"] / tmp[\"last_feat_demand\"].replace(0, np.nan)\n",
    "\n",
    "print(tmp[[\"country\",\"sku\",\"y_pred\",\"last_feat_demand\",\"ratio_pred_to_feat_last\",\"model_type\"]]\n",
    "      .sort_values(\"ratio_pred_to_feat_last\")\n",
    "      .head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "eb5c5d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "master_model_ready unique names:\n",
      "product_name\n",
      "GAZPACHO (17783-000)    2077\n",
      "Name: count, dtype: int64\n",
      "\n",
      "forecast_future unique names:\n",
      "product_name\n",
      "GAZPACHO (17783-000)    52\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "m = pd.read_parquet(\"data/master_model_ready.parquet\")\n",
    "g = m[(m[\"country\"]==\"Spain\") & (m[\"sku\"]==\"00119-066-001\")]\n",
    "print(\"master_model_ready unique names:\")\n",
    "print(g[\"product_name\"].value_counts())\n",
    "\n",
    "fc = pd.read_parquet(\"data/forecast_future.parquet\")\n",
    "g2 = fc[(fc[\"country\"]==\"Spain\") & (fc[\"sku\"]==\"00119-066-001\")]\n",
    "print(\"\\nforecast_future unique names:\")\n",
    "print(g2[\"product_name\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "f96a28ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing series for backtest: 9\n",
      "New backtest rows: 182\n",
      "Saved: C:\\Users\\48573\\Desktop\\Programy_rozwój\\TopYoung100\\HAVI\\data\\forecast_backtest.parquet (734, 8)\n",
      "Saved: C:\\Users\\48573\\Desktop\\Programy_rozwój\\TopYoung100\\HAVI\\data\\metrics_summary.parquet (20, 9)\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 09 -> ADD BACKTEST FOR MISSING SERIES (OTHER/FALLBACK)\n",
    "# Produces:\n",
    "# - data/forecast_backtest.parquet (appended)\n",
    "# - data/metrics_summary.parquet (optional summary)\n",
    "# =========================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"data\")\n",
    "BACKTEST_PATH = DATA_DIR / \"forecast_backtest.parquet\"\n",
    "METRICS_PATH  = DATA_DIR / \"metrics_summary.parquet\"\n",
    "\n",
    "H = 8  # horizon per cutoff (weeks) - możesz zmienić na 12 jeśli wolisz\n",
    "\n",
    "def wape(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true, dtype=float)\n",
    "    y_pred = np.asarray(y_pred, dtype=float)\n",
    "    denom = np.abs(y_true).sum()\n",
    "    return np.nan if denom <= 1e-12 else np.abs(y_true - y_pred).sum() / denom\n",
    "\n",
    "def mae(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true, dtype=float)\n",
    "    y_pred = np.asarray(y_pred, dtype=float)\n",
    "    return float(np.mean(np.abs(y_true - y_pred)))\n",
    "\n",
    "def bias(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true, dtype=float)\n",
    "    y_pred = np.asarray(y_pred, dtype=float)\n",
    "    return float(np.mean(y_pred - y_true))\n",
    "\n",
    "def naive_last(y_hist, horizon):\n",
    "    last = float(y_hist.iloc[-1]) if len(y_hist) else 0.0\n",
    "    return np.repeat(last, horizon)\n",
    "\n",
    "def seasonal_naive(y_hist, horizon, season=52):\n",
    "    if len(y_hist) < season:\n",
    "        return naive_last(y_hist, horizon)\n",
    "    start = len(y_hist) - season\n",
    "    return y_hist.iloc[start:start+horizon].values[:horizon]\n",
    "\n",
    "def drift(y_hist, horizon):\n",
    "    if len(y_hist) < 2:\n",
    "        return naive_last(y_hist, horizon)\n",
    "    slope = (float(y_hist.iloc[-1]) - float(y_hist.iloc[0])) / (len(y_hist) - 1)\n",
    "    return float(y_hist.iloc[-1]) + slope * np.arange(1, horizon + 1)\n",
    "\n",
    "# ---- LOAD EXISTING BACKTEST (if any) ----\n",
    "if BACKTEST_PATH.exists():\n",
    "    bt_existing = pd.read_parquet(BACKTEST_PATH)\n",
    "else:\n",
    "    bt_existing = pd.DataFrame()\n",
    "\n",
    "# ---- pick cutoff_dates ----\n",
    "# Prefer: use same cutoffs as existing backtest (so UI looks consistent)\n",
    "if not bt_existing.empty and \"cutoff_date\" in bt_existing.columns:\n",
    "    cutoff_dates = sorted(pd.to_datetime(bt_existing[\"cutoff_date\"]).dropna().unique())\n",
    "else:\n",
    "    # fallback: last 3 cutoffs from master_raw (monthly-ish)\n",
    "    all_dates = raw[\"week_start\"].dropna().sort_values().unique()\n",
    "    all_dates = pd.to_datetime(all_dates)\n",
    "    cutoff_dates = list(pd.Series(all_dates).iloc[-(H*3 + 10):].dropna().unique())\n",
    "    # pick 3 cutoffs spaced ~4 weeks\n",
    "    cutoff_dates = sorted(pd.to_datetime(cutoff_dates))[-3:]\n",
    "cutoff_dates = [pd.to_datetime(d) for d in cutoff_dates]\n",
    "\n",
    "# ---- determine which series are missing in backtest ----\n",
    "all_series = raw[[\"country\", \"sku\"]].drop_duplicates().copy()\n",
    "all_series[\"country\"] = all_series[\"country\"].astype(str)\n",
    "all_series[\"sku\"] = all_series[\"sku\"].astype(str)\n",
    "\n",
    "if not bt_existing.empty:\n",
    "    existing_series = bt_existing[[\"country\", \"sku\"]].drop_duplicates().copy()\n",
    "    existing_series[\"country\"] = existing_series[\"country\"].astype(str)\n",
    "    existing_series[\"sku\"] = existing_series[\"sku\"].astype(str)\n",
    "    missing_series = all_series.merge(existing_series, on=[\"country\",\"sku\"], how=\"left\", indicator=True)\n",
    "    missing_series = missing_series[missing_series[\"_merge\"]==\"left_only\"][[\"country\",\"sku\"]]\n",
    "else:\n",
    "    missing_series = all_series.copy()\n",
    "\n",
    "print(\"Missing series for backtest:\", len(missing_series))\n",
    "\n",
    "# ---- baseline map ----\n",
    "baseline_map = df_base.set_index([\"country\",\"sku\"])[\"best_baseline\"].astype(str).str.lower().to_dict()\n",
    "\n",
    "rows = []\n",
    "raw2 = raw.copy()\n",
    "raw2[\"country\"] = raw2[\"country\"].astype(str)\n",
    "raw2[\"sku\"] = raw2[\"sku\"].astype(str)\n",
    "raw2[\"week_start\"] = pd.to_datetime(raw2[\"week_start\"], errors=\"coerce\")\n",
    "raw2 = raw2[raw2[\"week_start\"].notna()].copy()\n",
    "raw2[\"demand_raw\"] = pd.to_numeric(raw2[\"demand_raw\"], errors=\"coerce\").fillna(0.0).clip(lower=0.0)\n",
    "\n",
    "for (c, sku) in missing_series[[\"country\",\"sku\"]].itertuples(index=False, name=None):\n",
    "    g = raw2[(raw2[\"country\"]==c) & (raw2[\"sku\"]==sku)].sort_values(\"week_start\")\n",
    "    if g.empty:\n",
    "        continue\n",
    "\n",
    "    y_all = g.set_index(\"week_start\")[\"demand_raw\"].astype(float)\n",
    "\n",
    "    model = baseline_map.get((c, sku), \"naive\").strip().lower()\n",
    "\n",
    "    for cd in cutoff_dates:\n",
    "        hist = y_all[y_all.index <= cd]\n",
    "        fut  = y_all[(y_all.index > cd)].head(H)\n",
    "\n",
    "        if len(hist) < 4 or len(fut) < 1:\n",
    "            continue\n",
    "\n",
    "        if model == \"seasonal_naive\":\n",
    "            pred = seasonal_naive(hist.reset_index(drop=True), len(fut), season=52)\n",
    "        elif model == \"drift\":\n",
    "            pred = drift(hist.reset_index(drop=True), len(fut))\n",
    "        else:\n",
    "            pred = naive_last(hist.reset_index(drop=True), len(fut))\n",
    "\n",
    "        pred = np.clip(np.asarray(pred, float), 0.0, None)\n",
    "\n",
    "        for d, yt, yp in zip(fut.index, fut.values, pred):\n",
    "            rows.append({\n",
    "                \"country\": c,\n",
    "                \"dc_id\": \"ALL\",\n",
    "                \"sku\": sku,\n",
    "                \"date\": pd.to_datetime(d),\n",
    "                \"cutoff_date\": pd.to_datetime(cd),\n",
    "                \"y_true\": float(yt),\n",
    "                \"y_pred_raw\": float(yp),\n",
    "                \"y_pred_cal\": float(yp),  # jeśli nie masz kalibracji -> kopia raw\n",
    "            })\n",
    "\n",
    "bt_new = pd.DataFrame(rows)\n",
    "print(\"New backtest rows:\", len(bt_new))\n",
    "\n",
    "# ---- append + save ----\n",
    "bt_all = pd.concat([bt_existing, bt_new], ignore_index=True)\n",
    "bt_all[\"date\"] = pd.to_datetime(bt_all[\"date\"], errors=\"coerce\")\n",
    "bt_all[\"cutoff_date\"] = pd.to_datetime(bt_all[\"cutoff_date\"], errors=\"coerce\")\n",
    "bt_all = bt_all.dropna(subset=[\"date\",\"cutoff_date\"])\n",
    "bt_all = bt_all.sort_values([\"country\",\"sku\",\"cutoff_date\",\"date\"])\n",
    "bt_all.to_parquet(BACKTEST_PATH, index=False)\n",
    "print(\"Saved:\", BACKTEST_PATH.resolve(), bt_all.shape)\n",
    "\n",
    "# ---- (optional) metrics_summary per series ----\n",
    "mrows = []\n",
    "for (c, sku), gg in bt_all.groupby([\"country\",\"sku\"], observed=True):\n",
    "    yt = gg[\"y_true\"].to_numpy(float)\n",
    "    yr = gg[\"y_pred_raw\"].to_numpy(float)\n",
    "    yc = gg[\"y_pred_cal\"].to_numpy(float)\n",
    "    mrows.append({\n",
    "        \"country\": str(c),\n",
    "        \"sku\": str(sku),\n",
    "        \"n_obs\": int(len(gg)),\n",
    "        \"WAPE_raw\": wape(yt, yr),\n",
    "        \"WAPE_cal\": wape(yt, yc),\n",
    "        \"MAE_raw\": mae(yt, yr),\n",
    "        \"MAE_cal\": mae(yt, yc),\n",
    "        \"Bias_raw\": bias(yt, yr),\n",
    "        \"Bias_cal\": bias(yt, yc),\n",
    "    })\n",
    "\n",
    "metrics_summary = pd.DataFrame(mrows).sort_values([\"WAPE_cal\",\"n_obs\"], ascending=[True, False])\n",
    "metrics_summary.to_parquet(METRICS_PATH, index=False)\n",
    "print(\"Saved:\", METRICS_PATH.resolve(), metrics_summary.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
